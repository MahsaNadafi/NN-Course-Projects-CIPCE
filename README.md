# Deep Neural Networks — Course Assignments (Fall 2022)

**School of Electrical and Computer Engineering, College of Engineering,  
University of Tehran, Tehran, Iran**

This repository contains my assignment submissions for the **Deep Neural Networks** course offered at the University of Tehran in Fall 2022, instructed by **Dr. Ahmad Kalhor**.

The assignments cover a broad set of foundational and advanced concepts in neural networks, including **perceptrons and logistic regression, multilayer feedforward networks, optimization and regularization, convolutional neural networks (CNNs), recurrent neural networks (RNNs), and autoencoders / representation learning**.

---

## Repository Structure

```text
NN-Course-Projects-CIPCE/
│
├── HW1/
├── HW2/
├── HW3/
├── HW4/
├── HW5/
├── HW6/
├── Extra Homework/
│
└── README.md
```

Each homework folder typically contains:
- Jupyter notebooks (`.ipynb`) with the implementation and experiments  
- Auxiliary scripts or data loaders (if needed)  

---

## Homework 1

**Topics Covered**
- Perceptron and logistic regression
- Basic feedforward neural networks
- Gradient descent and backpropagation

**[Open HW1 Folder](HW1/)**

---

## Homework 2

**Topics Covered**
- Deeper multilayer perceptrons (MLPs)
- Regularization (L2, early stopping, dropout)
- Optimization methods (SGD, momentum, Adam)

**[Open HW2 Folder](HW2/)**

---

## Homework 3

**Topics Covered**
- Convolutional Neural Networks (CNNs)
- Image classification on benchmark datasets (e.g., MNIST / CIFAR)
- Architectural design (filters, pooling, padding)

**[Open HW3 Folder](HW3/)**

---

## Homework 4

**Topics Covered**
- Recurrent Neural Networks (RNNs) and LSTMs/GRUs
- Sequence modeling (time series / text)
- Training stability and vanishing gradients

**[Open HW4 Folder](HW4/)**

---

## Homework 5

**Topics Covered**
- Autoencoders and representation learning
- Denoising and regularized autoencoders
- Dimensionality reduction and latent space visualization

**[Open HW5 Folder](HW5/)**

---

## Homework 6

**Topics Covered**
- Advanced deep learning techniques (e.g., batch normalization, residual connections)
- Model evaluation and generalization analysis
- Comparative experiments across architectures

**[Open HW6 Folder](HW6/)**

---

## Extra Homework

**Topics Covered**
- Bonus experiments and additional projects extending course concepts  
- Exploration of alternative architectures and training strategies

**[Open Extra Homework Folder](Extra%20Homework/)**

---

## Acknowledgments

Special thanks to **Dr. Ahmad Kalhor** for his guidance and teaching throughout the course.

---
